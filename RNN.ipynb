{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.Module -> Base class for all neural network modules in pytorch\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_size: final embedding size of the CNN encoder (256 in our case)\n",
    "            hidden_size: hidden size of the LSTM\n",
    "            vocab_size: size of the vocabulary - The total number of unique words the model knows.\n",
    "            num_layers: number of layers of the LSTM (1 by default here)\n",
    "        \"\"\"\n",
    "\n",
    "        # Calls the parent class (nn.Module) constructor, \n",
    "        # allowing this custom class to inherit its functionality.\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        # Assigning hidden dimension\n",
    "        # Stores the hidden state size for later use\n",
    "        self.hidden_dim = hidden_size\n",
    "\n",
    "        # Map each word in the vocabulary (represented as an integer index) \n",
    "        # to a dense embedding vector of embed_size\n",
    "        # Why? -> Converts the input captions (word indices) into continuous vectors that capture semantic meaning.\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "\n",
    "        # Creating LSTM layer\n",
    "        # batch_first=True: Indicates that input tensors will have the shape (batch_size, sequence_length, feature_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Initializing linear to apply at last of RNN layer for further prediction\n",
    "        # nn.Linear: Fully connected (dense) layer that maps the LSTM’s hidden state output to a vocabulary-sized tensor.\n",
    "        # Why? -> Converts the LSTM’s output into logits (unnormalized scores) for each word in the vocabulary.\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "        # Initializes the hidden state and cell state of the LSTM to zeros.\n",
    "        # Shape: (num_layers, batch_size, hidden_size)\n",
    "        self.hidden = (torch.zeros(1, 1, hidden_size), torch.zeros(1, 1, hidden_size))\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "    # model processes inputs to produce outputs.\n",
    "        \n",
    "        # remove <end> token from captions and embed captions\n",
    "        # This is because we want to predict the next word, not the <end> token.\n",
    "        # self.embed: Converts the word indices into embedding vectors.\n",
    "        cap_embedding = self.embed(\n",
    "            captions[:, :-1]\n",
    "        )  # (bs, cap_length) -> (bs, cap_length-1, embed_size)\n",
    "\n",
    "\n",
    "        # torch.cat: Concatenates the image features and caption embeddings along the sequence dimension.\n",
    "        # features.unsqueeze(dim=1): Adds a dimension to the features tensor, making it (batch_size, 1, embed_size).\n",
    "        # [bs, embed_size] => [bs, 1, embed_size] concat [bs, cap_length-1, embed_size]\n",
    "\n",
    "        # => [bs, cap_length, embed_size] add encoded image (features) as t=0\n",
    "        # This adds the image feature as the first time step of the sequence, which helps the decoder generate captions.\n",
    "        embeddings = torch.cat((features.unsqueeze(dim=1), cap_embedding), dim=1)\n",
    "\n",
    "\n",
    "        # self.lstm: Processes the combined embeddings through the LSTM.\n",
    "        # getting output i.e. score and hidden layer.\n",
    "\n",
    "        # first value: all the output hidden states for each time stamp throughout the sequence. \n",
    "        # second value: Final hidden and cell states of the LSTM\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeddings\n",
    "        )  # lstm_out shape -> (bs, cap_length, hidden_size), \n",
    "           # hidden shape -> (num_layers = 1, bs, hidden_size)\n",
    "\n",
    "        \n",
    "        # self.linear: Applies a fully connected layer to map LSTM outputs to vocabulary scores.\n",
    "        outputs = self.linear(lstm_out)  # (bs, cap_length, vocab_size)\n",
    "\n",
    "        # A tensor of shape (batch_size, caption_length, vocab_size) \n",
    "        # containing scores for each word in the vocabulary at each time step.\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def sample(self, inputs, states=None, max_len=20):\n",
    "       # Generates a predicted sentence (with word IDs) based on the provided pre-processed image tensor.\n",
    "\n",
    "        # Initialize an empty list to store the predicted word indices\n",
    "        res = []\n",
    "\n",
    "        # Now we feed the LSTM output and hidden states back into itself to get the caption\n",
    "        for i in range(max_len):\n",
    "\n",
    "            # Pass the input through the LSTM to get the output and updated states. lstm_out: (1, 1, hidden_size)\n",
    "            lstm_out, states = self.lstm(inputs, states)  \n",
    "\n",
    "            # Pass the LSTM output through the linear layer to get predictions over the vocabulary. outputs: (1, vocab_size)\n",
    "            outputs = self.linear(lstm_out.squeeze(dim=1))  \n",
    "\n",
    "            # Select the word index with the highest score (most probable word)\n",
    "            _, predicted_idx = outputs.max(dim=1)  # predicted: (1, 1)\n",
    "\n",
    "            res.append(predicted_idx.item())\n",
    "\n",
    "            # if the predicted idx is the stop index, the loop stops\n",
    "            if predicted_idx == 1:\n",
    "                break\n",
    "            \n",
    "             # Embed the predicted word index to get the input for the next iteration. inputs: (1, embed_size)\n",
    "            inputs = self.embed(predicted_idx)  \n",
    "\n",
    "            # prepare input for next iteration\n",
    "            inputs = inputs.unsqueeze(1)  # inputs: (1, 1, embed_size)\n",
    "\n",
    "        return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
